{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting It All Together\n",
    "\n",
    "As you might have guessed from the last notebook, using all of the variables was allowing you to drastically overfit the training data.  This was great for looking good in terms of your Rsquared on these points.  However, this was not great in terms of how well you were able to predict on the test data.\n",
    "\n",
    "We will start where we left off in the last notebook.  First read in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Professional</th>\n",
       "      <th>ProgramHobby</th>\n",
       "      <th>Country</th>\n",
       "      <th>University</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>MajorUndergrad</th>\n",
       "      <th>HomeRemote</th>\n",
       "      <th>CompanySize</th>\n",
       "      <th>...</th>\n",
       "      <th>StackOverflowMakeMoney</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HighestEducationParents</th>\n",
       "      <th>Race</th>\n",
       "      <th>SurveyLong</th>\n",
       "      <th>QuestionsInteresting</th>\n",
       "      <th>QuestionsConfusing</th>\n",
       "      <th>InterestedAnswers</th>\n",
       "      <th>Salary</th>\n",
       "      <th>ExpectedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Student</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Not employed, and not looking for work</td>\n",
       "      <td>Secondary school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>High school</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Student</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Yes, full-time</td>\n",
       "      <td>Employed part-time</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>More than half, but not all, the time</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>...</td>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A master's degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Professional developer</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>Less than half the time, but at least one day ...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>...</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A professional degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>113750.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Professional non-developer who sometimes write...</td>\n",
       "      <td>Yes, both</td>\n",
       "      <td>United States</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>A non-computer-focused engineering discipline</td>\n",
       "      <td>Less than half the time, but at least one day ...</td>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>...</td>\n",
       "      <td>Disagree</td>\n",
       "      <td>Male</td>\n",
       "      <td>A doctoral degree</td>\n",
       "      <td>White or of European descent</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Professional developer</td>\n",
       "      <td>Yes, I program as a hobby</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed full-time</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Computer science or software engineering</td>\n",
       "      <td>Never</td>\n",
       "      <td>10 to 19 employees</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Respondent                                       Professional  \\\n",
       "0           1                                            Student   \n",
       "1           2                                            Student   \n",
       "2           3                             Professional developer   \n",
       "3           4  Professional non-developer who sometimes write...   \n",
       "4           5                             Professional developer   \n",
       "\n",
       "                ProgramHobby         Country      University  \\\n",
       "0                  Yes, both   United States              No   \n",
       "1                  Yes, both  United Kingdom  Yes, full-time   \n",
       "2                  Yes, both  United Kingdom              No   \n",
       "3                  Yes, both   United States              No   \n",
       "4  Yes, I program as a hobby     Switzerland              No   \n",
       "\n",
       "                         EmploymentStatus  \\\n",
       "0  Not employed, and not looking for work   \n",
       "1                      Employed part-time   \n",
       "2                      Employed full-time   \n",
       "3                      Employed full-time   \n",
       "4                      Employed full-time   \n",
       "\n",
       "                                     FormalEducation  \\\n",
       "0                                   Secondary school   \n",
       "1  Some college/university study without earning ...   \n",
       "2                                  Bachelor's degree   \n",
       "3                                    Doctoral degree   \n",
       "4                                    Master's degree   \n",
       "\n",
       "                                  MajorUndergrad  \\\n",
       "0                                            NaN   \n",
       "1       Computer science or software engineering   \n",
       "2       Computer science or software engineering   \n",
       "3  A non-computer-focused engineering discipline   \n",
       "4       Computer science or software engineering   \n",
       "\n",
       "                                          HomeRemote  \\\n",
       "0                                                NaN   \n",
       "1              More than half, but not all, the time   \n",
       "2  Less than half the time, but at least one day ...   \n",
       "3  Less than half the time, but at least one day ...   \n",
       "4                                              Never   \n",
       "\n",
       "                CompanySize  ... StackOverflowMakeMoney Gender  \\\n",
       "0                       NaN  ...      Strongly disagree   Male   \n",
       "1        20 to 99 employees  ...      Strongly disagree   Male   \n",
       "2  10,000 or more employees  ...               Disagree   Male   \n",
       "3  10,000 or more employees  ...               Disagree   Male   \n",
       "4        10 to 19 employees  ...                    NaN    NaN   \n",
       "\n",
       "  HighestEducationParents                          Race         SurveyLong  \\\n",
       "0             High school  White or of European descent  Strongly disagree   \n",
       "1       A master's degree  White or of European descent     Somewhat agree   \n",
       "2   A professional degree  White or of European descent     Somewhat agree   \n",
       "3       A doctoral degree  White or of European descent              Agree   \n",
       "4                     NaN                           NaN                NaN   \n",
       "\n",
       "  QuestionsInteresting QuestionsConfusing InterestedAnswers    Salary  \\\n",
       "0       Strongly agree           Disagree    Strongly agree       NaN   \n",
       "1       Somewhat agree           Disagree    Strongly agree       NaN   \n",
       "2                Agree           Disagree             Agree  113750.0   \n",
       "3                Agree     Somewhat agree    Strongly agree       NaN   \n",
       "4                  NaN                NaN               NaN       NaN   \n",
       "\n",
       "   ExpectedSalary  \n",
       "0             NaN  \n",
       "1         37500.0  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import AllTogether as t\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./survey_results_public.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "**1.** To begin fill in the format function below with the correct variable.  Notice each **{ }** holds a space where one of your variables will be added to the string.  This will give you something to do while the the function does all the steps you did throughout this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order to understand how well our linear model (lm_model) fit the dataset, \n",
      "            we first needed to split our data into train and test data sets.  \n",
      "            Then we were able to fit our linear model (lm_model) on the X_train and y_train.  \n",
      "            We could then predict using our linear model (lm_model)  by providing \n",
      "            the linear model the X_test for it to make predictions.  \n",
      "            These predictions were for y_test. \n",
      "\n",
      "            By looking at the train_score, it looked like we were doing awesome because \n",
      "            it was 1!  However, looking at the test_score suggested our model was not \n",
      "            extending well.  The purpose of this notebook will be to see how \n",
      "            well we can get our model to extend to new data.\n",
      "            \n",
      "            This problem where our data fits the training data well, but does\n",
      "            not perform well on test data is commonly known as \n",
      "            overfitting.\n"
     ]
    }
   ],
   "source": [
    "a = 'test_score'\n",
    "b = 'train_score'\n",
    "c = 'linear model (lm_model)'\n",
    "d = 'X_train and y_train'\n",
    "e = 'X_test'\n",
    "f = 'y_test'\n",
    "g = 'train and test data sets'\n",
    "h = 'overfitting'\n",
    "\n",
    "q1_piat = '''In order to understand how well our {} fit the dataset, \n",
    "            we first needed to split our data into {}.  \n",
    "            Then we were able to fit our {} on the {}.  \n",
    "            We could then predict using our {}  by providing \n",
    "            the linear model the {} for it to make predictions.  \n",
    "            These predictions were for {}. \n",
    "\n",
    "            By looking at the {}, it looked like we were doing awesome because \n",
    "            it was 1!  However, looking at the {} suggested our model was not \n",
    "            extending well.  The purpose of this notebook will be to see how \n",
    "            well we can get our model to extend to new data.\n",
    "            \n",
    "            This problem where our data fits the training data well, but does\n",
    "            not perform well on test data is commonly known as \n",
    "            {}.'''.format(c, g, c, d, c, e, f, b, a, h) #replace a with the correct variable\n",
    "\n",
    "print(q1_piat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This one is tricky - here is the order of the letters for the solution we had in mind:\n",
      " c, g, c, d, c, e, f, b, a, h\n"
     ]
    }
   ],
   "source": [
    "# Print the solution order of the letters in the format\n",
    "t.q1_piat_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "**2.** Now, we need to improve the model . Use the dictionary below to provide the true statements about improving **this model**.  **Also consider each statement as a stand alone**.  Though, it might be a good idea after other steps, which would you consider a useful **next step**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'yes'\n",
    "b = 'no'\n",
    "\n",
    "q2_piat = {'add interactions, quadratics, cubics, and other higher order terms': b, \n",
    "           'fit the model many times with different rows, then average the responses': a,\n",
    "           'subset the features used for fitting the model each time': a,\n",
    "           'this model is hopeless, we should start over': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job! That looks right!  These two techniques are really common in Machine Learning algorithms to combat overfitting.  Though the first technique could be useful, it is not likely to help us right away with our current model.  These additional features would likely continue to worsen the nature of overfitting we are seeing here.\n"
     ]
    }
   ],
   "source": [
    "#Check your solution\n",
    "t.q2_piat_check(q2_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3\n",
    "\n",
    "**3.** Before we get too far along, follow the steps in the function below to create the X (explanatory matrix) and y (response vector) to be used in the model.  If your solution is correct, you should see a plot similar to the one shown in the Screencast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "    INPUT\n",
    "    df - pandas dataframe \n",
    "    \n",
    "    OUTPUT\n",
    "    X - A matrix holding all of the variables you want to consider when predicting the response\n",
    "    y - the corresponding response vector\n",
    "    \n",
    "    Perform to obtain the correct X and y objects\n",
    "    This function cleans df using the following steps to produce X and y:\n",
    "    1. Drop all the rows with no salaries\n",
    "    2. Create X as all the columns that are not the Salary column\n",
    "    3. Create y as the Salary column\n",
    "    4. Drop the Salary, Respondent, and the ExpectedSalary columns from X\n",
    "    5. For each numeric variable in X, fill the column with the mean value of the column.\n",
    "    6. Create dummy columns for all the categorical variables in X, drop the original columns\n",
    "    '''\n",
    "    #     1. Drop all the rows with no salaries\n",
    "    df = df.dropna(subset=['Salary'], axis=0)\n",
    "    #    2. Create X as all the columns that are not the Salary column\n",
    "    y = df['Salary']\n",
    "    df = df.drop(['Respondent', 'ExpectedSalary', 'Salary'], axis=1)\n",
    "    #    3. Fill numeric columns with the mean\n",
    "    num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "    for col in num_vars:\n",
    "        df[col].fillna((df[col].mean()), inplace=True)\n",
    "    #    4. Dummy the categorical variables\n",
    "    cat_vars = df.select_dtypes(include=['object']).columns\n",
    "    for var in cat_vars:\n",
    "        df = pd.concat([df.drop(var, axis=1), pd.get_dummies(df[var], prefix=var, prefix_sep='-', drop_first=True)], axis=1)\n",
    "    \n",
    "    X = df\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "#Use the function to create X and y\n",
    "X, y = clean_data(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Cell Below to Acheive the Results Needed for Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloe/opt/anaconda3/envs/DS-env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cutoffs here pertains to the number of missing values allowed in the used columns.\n",
    "#Therefore, lower values for the cutoff provides more predictors in the model.\n",
    "cutoffs = [5000, 3500, 2500, 1000, 100, 50, 30, 25]\n",
    "\n",
    "#Run this cell to pass your X and y to the model for testing\n",
    "r2_scores_test, r2_scores_train, lm_model, X_train, X_test, y_train, y_test = t.find_optimal_lm_mod(X, y, cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "**4.** Use the output and above plot to correctly fill in the keys of the **q4_piat** dictionary with the correct variable.  Notice that only the optimal model results are given back in the above - they are stored in **lm_model**, **X_train**, **X_test**, **y_train**, and **y_test**.  If more than one answer holds, provide a tuple holding all the correct variables in the order of first variable alphabetically to last variable alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6936337725934354\n",
      "0.8211155717267258\n"
     ]
    }
   ],
   "source": [
    "# Cell for your computations to answer the next question\n",
    "X_train.shape\n",
    "print(r2_scores_test[np.argmax(r2_scores_test)]) # The model we should implement test_r2\n",
    "print(r2_scores_train[np.argmax(r2_scores_test)]) # The model we should implement train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'we would likely have a better rsquared for the test data.'\n",
    "b = 1000\n",
    "c = 872\n",
    "d = 0.69\n",
    "e = 0.82\n",
    "f = 0.88\n",
    "g = 0.72\n",
    "h = 'we would likely have a better rsquared for the training data.'\n",
    "\n",
    "q4_piat = {'The optimal number of features based on the results is': c, \n",
    "               'The model we should implement in practice has a train rsquared of': e, \n",
    "               'The model we should implement in practice has a test rsquared of': d,\n",
    "               'If we were to allow the number of features to continue to increase': h\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job! That looks right!  We can see that the model we should impement was the 6th model using 1088 features.  It is the model that has the best test rsquared value.\n"
     ]
    }
   ],
   "source": [
    "#Check against your solution\n",
    "t.q4_piat_check(q4_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "**5.** The default penalty on coefficients using linear regression in sklearn is a ridge (also known as an L2) penalty.  Because of this penalty, and that all the variables were normalized, we can look at the size of the coefficients in the model as an indication of the impact of each variable on the salary.  The larger the coefficient, the larger the expected impact on salary.  \n",
    "\n",
    "Use the space below to take a look at the coefficients.  Then use the results to provide the **True** or **False** statements based on the data.\n",
    "\n",
    "#### Run the below to complete the following dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>est_int</th>\n",
       "      <th>coefs</th>\n",
       "      <th>abs_coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Country-United States</td>\n",
       "      <td>55281.225281</td>\n",
       "      <td>55281.225281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Country-Norway</td>\n",
       "      <td>54469.173923</td>\n",
       "      <td>54469.173923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Country-Australia</td>\n",
       "      <td>42745.068641</td>\n",
       "      <td>42745.068641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Currency-Swiss francs</td>\n",
       "      <td>42339.353397</td>\n",
       "      <td>42339.353397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Country-Denmark</td>\n",
       "      <td>35599.977732</td>\n",
       "      <td>35599.977732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>YearsCodedJob-18 to 19 years</td>\n",
       "      <td>34767.946905</td>\n",
       "      <td>34767.946905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Country-Israel</td>\n",
       "      <td>33837.308852</td>\n",
       "      <td>33837.308852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Country-New Zealand</td>\n",
       "      <td>30354.907073</td>\n",
       "      <td>30354.907073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>YearsCodedJob-20 or more years</td>\n",
       "      <td>29531.537917</td>\n",
       "      <td>29531.537917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Country-Switzerland</td>\n",
       "      <td>28531.983377</td>\n",
       "      <td>28531.983377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>YearsCodedJob-17 to 18 years</td>\n",
       "      <td>27237.020938</td>\n",
       "      <td>27237.020938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Country-Ireland</td>\n",
       "      <td>26916.058624</td>\n",
       "      <td>26916.058624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Country-Ukraine</td>\n",
       "      <td>-25433.248732</td>\n",
       "      <td>25433.248732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>YearsCodedJob-14 to 15 years</td>\n",
       "      <td>25152.531761</td>\n",
       "      <td>25152.531761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Country-Germany</td>\n",
       "      <td>21657.888047</td>\n",
       "      <td>21657.888047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>YearsCodedJob-12 to 13 years</td>\n",
       "      <td>21204.254527</td>\n",
       "      <td>21204.254527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>YearsCodedJob-19 to 20 years</td>\n",
       "      <td>21118.233275</td>\n",
       "      <td>21118.233275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>YearsCodedJob-13 to 14 years</td>\n",
       "      <td>20929.891413</td>\n",
       "      <td>20929.891413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Currency-Mexican pesos (MXN$)</td>\n",
       "      <td>-19925.752964</td>\n",
       "      <td>19925.752964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>YearsCodedJob-15 to 16 years</td>\n",
       "      <td>19581.282317</td>\n",
       "      <td>19581.282317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            est_int         coefs     abs_coefs\n",
       "36            Country-United States  55281.225281  55281.225281\n",
       "24                   Country-Norway  54469.173923  54469.173923\n",
       "7                 Country-Australia  42745.068641  42745.068641\n",
       "349           Currency-Swiss francs  42339.353397  42339.353397\n",
       "13                  Country-Denmark  35599.977732  35599.977732\n",
       "110    YearsCodedJob-18 to 19 years  34767.946905  34767.946905\n",
       "19                   Country-Israel  33837.308852  33837.308852\n",
       "23              Country-New Zealand  30354.907073  30354.907073\n",
       "113  YearsCodedJob-20 or more years  29531.537917  29531.537917\n",
       "33              Country-Switzerland  28531.983377  28531.983377\n",
       "109    YearsCodedJob-17 to 18 years  27237.020938  27237.020938\n",
       "18                  Country-Ireland  26916.058624  26916.058624\n",
       "34                  Country-Ukraine -25433.248732  25433.248732\n",
       "106    YearsCodedJob-14 to 15 years  25152.531761  25152.531761\n",
       "16                  Country-Germany  21657.888047  21657.888047\n",
       "104    YearsCodedJob-12 to 13 years  21204.254527  21204.254527\n",
       "111    YearsCodedJob-19 to 20 years  21118.233275  21118.233275\n",
       "105    YearsCodedJob-13 to 14 years  20929.891413  20929.891413\n",
       "344   Currency-Mexican pesos (MXN$) -19925.752964  19925.752964\n",
       "107    YearsCodedJob-15 to 16 years  19581.282317  19581.282317"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coef_weights(coefficients, X_train):\n",
    "    '''\n",
    "    INPUT:\n",
    "    coefficients - the coefficients of the linear model \n",
    "    X_train - the training data, so the column names can be used\n",
    "    OUTPUT:\n",
    "    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n",
    "    \n",
    "    Provides a dataframe that can be used to understand the most influential coefficients\n",
    "    in a linear model by providing the coefficient estimates along with the name of the \n",
    "    variable attached to the coefficient.\n",
    "    '''\n",
    "    coefs_df = pd.DataFrame()\n",
    "    coefs_df['est_int'] = X_train.columns\n",
    "    coefs_df['coefs'] = lm_model.coef_\n",
    "    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n",
    "    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n",
    "    return coefs_df\n",
    "\n",
    "#Use the function\n",
    "coef_df = coef_weights(lm_model.coef_, X_train)\n",
    "\n",
    "#A quick look at the top results\n",
    "coef_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = True\n",
    "b = False\n",
    "\n",
    "#According to the data...\n",
    "q5_piat = {'Country appears to be one of the top indicators for salary': a,\n",
    "               'Gender appears to be one of the indicators for salary': b, \n",
    "               'How long an individual has been programming appears to be one of the top indicators for salary': a,\n",
    "               'The longer an individual has been programming the more they are likely to earn': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job! That looks right! The country and years of experience both seem to have a significant impact on the salary of individuals.\n"
     ]
    }
   ],
   "source": [
    "t.q5_piat_check(q5_piat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congrats of some kind\n",
    "\n",
    "Congrats!  Hopefully this was a great review, or an eye opening experience about how to put the steps together for an analysis.  List the steps.  In the next lesson, you will look at how take this and show it off to others so they can act on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "76701042e3a62d8ca3c353dee0b43944fe83a79f95a1e7f0310c0ac7201e2e7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
